## Cross Validation ##
## KFold, StratifiedKFold, cross_val_score, GridSearchCV ##

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold
import numpy as np

iris = load_iris()
features = iris.data
label = iris.target
dt_clf = DecisionTreeClassifier(random_state=121)

#### KFOLD ####

kfold = KFold(n_splits=5) # KFold object
fold_accuracy = [] # accuracy per each fold
print('iris data shape: ', features.shape) # (150, 4)

n_iter = 0

for train_index, test_index in kfold.split(features): # kfold.split: train, test row index (per fold) returned as array
    x_train, x_test = features[train_index], features[test_index]
    y_train, y_test = label[train_index], label[test_index]
    
    dt_clf.fit(x_train, y_train)
    pred = dt_clf.predict(x_test)
    n_iter += 1
    
    acc = np.round(accuracy_score(y_test, pred), 4)
    train_size = x_train.shape[0]
    test_size = x_test.shape[0]
    print("#n#{0} kfold cross validation accuracy: {1}, train size: {2}, test size: {3}".format(n_iter, acc, train_size, test_size))
    print("#{0} test index: {1}".format(n_iter, test_index))
    print()
    # example
    # #n#1 cross validation accuracy: 1.0, train size: 120, test size: 30
    # #1 test index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
    #                 24 25 26 27 28 29]
    
    fold_accuracy.append(acc)

print("## average validation accuracy: ", np.mean(fold_accuracy))  


#### Stratified KFOLD ####

import pandas as pd

iris = load_iris()
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['label']=iris.target
iris_df['label'].value_counts()

from sklearn.model_selection import StratifiedKFold

skfold = StratifiedKFold(n_splits=5)
n_iter = 0

for train_index, test_index in skfold.split(iris_df, iris_df['label']): # for stratified KFold, we need label data
    n_iter += 1
    label_train = iris_df['label'].iloc[train_index]
    label_test = iris_df['label'].iloc[test_index]
    print("\n## cross validation {0}".format(n_iter))
    print("## train label data distribution\n", label_train.value_counts())
    print("## test label data distribution\n", label_test.value_counts())
    # example
    # ## cross validation 1
    # ## train label data distribution
    # 2    40
    # 1    40
    # 0    40
    # Name: label, dtype: int64
    ## test label data distribution
    # 2    10
    # 1    10
    # 0    10
    # Name: label, dtype: int64

dt_clf = DecisionTreeClassifier(random_state=121)

skfold = StratifiedKFold(n_splits=5)
n_iter = 0
skfold_accuracy = []

for train_index, test_index in skfold.split(features, label): # label dataset necessary
    x_train, x_test = features[train_index], features[test_index]
    y_train, y_test = label[train_index], label[test_index]
    
    dt_clf.fit(x_train, y_train)
    pred = dt_clf.predict(x_test)
    
    n_iter += 1
    acc = np.round(accuracy_score(y_test, pred), 4)
    train_size = x_train.shape[0]
    test_size = x_test.shape[0]
    
    print("##{0} stratified cross validation accuracy: {1}, train data size: {2}, test data size: {3}".format(n_iter, acc, train_size, test_size))
    print("##{0} test index: {1}".format(n_iter, test_index))
    print()
    
    # example
    # ##1 stratified cross validation accuracy: 0.9667, train data size: 120, test data size: 30
    # ##1 test index: [  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57
    #                  58  59 100 101 102 103 104 105 106 107 108 109]
    
    skfold_accuracy.append(acc)

print("## all stratified cross validation accuracy: ", np.round(skfold_accuracy, 4)) # [0.9667 0.9667 0.9    0.9667 1.    ]
print("## average cross validation accuracy: ", np.mean(skfold_accuracy)) # 0.9600200000000001

#### cross_val_score() ####
# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html

from sklearn.model_selection import cross_val_score, cross_validate
import numpy as np

iris = load_iris()
dt_clf = DecisionTreeClassifier(random_state=123)

iris_data = iris.data
iris_label = iris.target
scores = cross_val_score(dt_clf, iris_data, iris_label, scoring='accuracy', cv=3) # cv = cross validation set
print("cross validation accuracy: ", np.round(scores, 4)) # [0.98 0.94 0.98]
print("average validation accuracy: ", np.round(np.mean(scores), 4)) # 0.9667


#### GridSearchCV ####
# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html
from sklearn.model_selection import GridSearchCV, train_test_split

iris = load_iris()
x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=125)
dt_clf = DecisionTreeClassifier()
parameters = {'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}

# use param_grid as hyper parameters
# refit=True default, if it's True, it will retrain model with the best parameter settings
grid_dt_clf = GridSearchCV(dt_clf, param_grid=parameters, cv=3, refit=True, return_train_score=True)

grid_dt_clf.fit(x_train, y_train)

# result of GridSearchCV is saved with the name of cv_results_ (dictionary)
scores_df = pd.DataFrame(grid_dt_clf.cv_results_)
scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]

grid_dt_clf.cv_results_

print("GridSearchCV best parameter: ", grid_dt_clf.best_params_) # GridSearchCV best parameter:  {'max_depth': 2, 'min_samples_split': 2}
print("GridSearchCV best accuracy: {0:.4f}".format(grid_dt_clf.best_score_)) # GridSearchCV best accuracy: 0.9417

# refit = True, so GridSearchCV object contain estimator after fit -> it can predict as well
pred = grid_dt_clf.predict(x_test)
print("test data accuracy: {0:.4f}".format(accuracy_score(y_test, pred))) # test data accuracy: 0.9333

estimator = grid_dt_clf.best_estimator_ # refit = True, so it is already trained with best parameters
pred = estimator.predict(x_test)
print("test data accuracy: {0:.4f}".format(accuracy_score(y_test, pred))) # test data accuracy: 0.9333
